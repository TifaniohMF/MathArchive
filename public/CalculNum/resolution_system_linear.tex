\documentclass[a4paper,12pt]{article}

% ------------------------
% IMPORTATION DES PACKAGES
% ------------------------

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=2cm]{geometry}
\usepackage{amsfonts}
\usepackage{lmodern}
\usepackage[french]{babel}

\date{}
\author{}
\title{Résolution de système linéaire}
\renewcommand{\familydefault}{\sfdefault}

\begin{document}
\maketitle
Un système d'équation linéaire est un ensemble d'équation sous la forme :
$$\left\lbrace\begin{array}{lll}
    a_{11}x_{1} \: + \: a_{12}x_{2} \: + \: \cdots \: + \: a_{1n}x_{n} & = & b_{1} \\
    a_{21}x_{1} \: + \: a_{22}x_{2} \: + \: \cdots \: + \: a_{2n}x_{n} & = & b_{2} \\
    \vdots &  & \vdots \\
    a_{n1}x_{1} \: + \: a_{n2}x_{2} \: + \: \cdots \: + \: a_{nn}x_{n} & = & b_{n} \\
\end{array} \right .$$

\section*{Forme matricielle}
Un système d'équation linéaire peut aussi s'écrire sous forme $Ax=b \; ou \; A \in M_{mn}(\mathbb{K}),\; x \in \mathbb{K}^{n} \; et \; b \in \mathbb{K}^{m}$
$$A = \left(\begin{array}{cccc}
    a_{11} & a_{12} & \cdots & a_{1n} \\
    a_{21} & a_{22} & \cdots & a_{2n} \\
    \vdots & \vdots & \ddots & \vdots \\
    a_{m1} & a_{m2} & \cdots & a_{mn} \\
    \end{array}\right) ; 
    x = \left(\begin{array}{cccc}
    x_{1}\\
    x_{2}\\
    \vdots \\
    x_{n} \\
    \end{array}\right)
    \; et \; 
    b = \left(\begin{array}{ccc}
    b_{1}\\
    b_{2}\\
    \vdots \\
    b_{n} \\
    \end{array}\right)$$


\section*{Définition}
Le rang d'une matrice notée $rg(A)$ est le nombre maximum de vecteurs ligne (ou colonne) linéairement indépendant.\\
\textbf{Rémarque}:\\ Si $A \in M_{mn}(\mathbf{K}) \; alors \; rg(A) \leq \min(m,n)$

\section*{Résolution de système linéaire avec matrice carrée}
\subsection*{Décomposition en LU}
On suppose que $A \in Gl_{n}(\mathbb{K})$ et on considère que le systeme linéaire $Ax=b$. L'idée est de décomposer $A=LU$ avec $\mathit{L}$ un matrice triangulaire inférieur et $\mathit{U}$ un matrice triangulaire supérieur.\\
Pour résoudre $Ax=b$ en 2 étape :
\begin{itemize}
    \item[-] Résoudre l'équation $Ly=b$ pour $y=Ux$
    \item[-] Puis résoudre $Ux=y$
\end{itemize}    
Il faut environ $\frac{2}{3}n^{3}$ pour calculer \textit{LU} et pour résoudre un système triangulaire il faut $n^2$ opération.\\
\textbf{Application}:\\
\textbf{Calcul de déterminant et inverse}:\\
Une fois obtenu la décomposition $LU$ on a $$A=LU \equiv detA\:=\:detL\:detU$$
Or si $detL=1\:(resp\:detU=1)$ on a : $$detA\:=\:detU=\prod_{i=1}^{n} u_{ii}(resp\:detA\:=\:detU=\prod_{i=1}^{n} l_{ii}).$$
Pour l'inverse on note $A^{-1}=(x_{1}|x_{2}| \cdots |x_{n})$ ou chacun des vecteurs $x_{i}$ est solution de $Ax_{i}=e_{i}$.\\ \\
\textbf{Algorithme}:\\
Entrée : A \\
Sortie : L,U \\
\begin{itemize}
\item[-] \textbf{Si on suppose que les diagonales de L vaut 1}
Composant de la matrice L :
$$ l_{ij} = \frac{1}{u_{jj}}(a_{ij}-\sum_{k=1}^{j-1}l_{ik}u_{kj}) $$
Composant de la matrice U :
$$ u_{ij} = a_{ij} - \sum_{k=1}^{i-1}l_{ik}u_{kj}$$
\item[-] \textbf{Si on suppose que les diagonales de U vaut 1}
Composant de la matrice L :
$$ l_{ij} = a_{ij} - \sum_{k=1}^{j-1}l_{ik}u_{kj} $$
Composant de la matrice U :
$$ u_{ij} = \frac{1}{l_{ii}}(a_{ij} - \sum_{k=1}^{i-1}l_{ik}u_{kj})$$
\end{itemize}
\section*{Décomposition QR}
On suppose que $A \in Gl_{n}(\mathbb{K})$. 
L'idée est de décomposer $A=QR$ avec $\mathit{Q}$ un matrice orthogonale ($QQ^{t}=Q^{t}Q=I$) et $\mathit{R}$ un matrice triangulaire supérieur.
Pour pouvoir faciliter la résolution de $Ax=b$. On écrit $Ax=b \equiv QRx=b$, on multiplie membre à membre par $Q^{t}$ et on obtient $Rx=Q^{t}b$.\\
\textbf{Remarque}:\\ cette décomposition QR existe toujours.\\
\textbf{Algorithme}:\\
Entrée : A \\
Sortie : Q,R \\
Notons $[q_{1},q_{2},\cdots,q_{n}] \; et \; [a_{1},a_{2},\cdots,a_{n}]$ les vécteurs colonnes réspectifs des matrices Q et A.\\
Pour trouver Q : $$ Posons \; u_{1}=a_{1} \; ; \; q_{1}=\frac{u_{1}}{\|u_{1}\|}$$
Pour j=2,3,...,n: $$u_{j} = a_{j} - \sum_{i=1}^{j-1}<a_{j},q_{i}>q_{i} \; ; \; q_{j}=\frac{u_{j}}{\|u_{j}\|}$$
Pour trouver R, on résout l'équation $R=Q^{t}A$.

\section*{Méthode de Cholesky}
\subsection*{Théoreme}
Soit $A \in M_{n}(\mathbf{R})$ une matrice symétrique définie positive alors, il existe un unique $B \in M_{n}(\mathbf{R})$ triangulaire inférieur de coefficient diagonaux strictément positive tel que $A=BB^{t}$.\\
Cette décomposition est appelée décompositionn de Cholesky.
\textbf{Algorithme}: \\
Entrée : A \\
Sortie : B \\
Diagonal :  $$b_{jj}=\sqrt{a_{jj}-\sum_{k=1}^{j}b_{jk}^{2}}$$
Non diagonaux : $$ b_{ij} = \frac{1}{b_{jj}}(a_{ij} - \sum_{k=1}^{j-1}b_{i}{k}b_{jk})$$

\section*{Calcul des valeurs propre et vecteurs propre}
\subsection*{Détermination du polyônme caractéristique}
Pour trouver les éléments propre de la matrice A, la méthode la plus simple consiste à trouver la polynôme caractéristique de A, à rechercher les zéros $\lambda_{1},\lambda_{2},\cdots,\lambda{n}$ puis à résoudre le système linéaire $Ax=\lambda_{i}x$.
Malheuresement, ce schema n'est pas satisfaisant pour les applications numeriques.
Toutefois, la connaissance du polynôme caractéristique peut être elle même utile indépendement de la recherche des valeurs propres.
Par la suite, on notera $P_{A}(X)=a_{0}X^{n}+a_{1}X^{n-1}+\cdots+a_{n} (a_{n} \not= 0)$ le polynôme caractéristique de la matrice A.

\section*{Méthode de Leverrier}
Soient $x_{1},x_{2},\cdots,x_{n}$ les valeurs propres $i.e$ les zéros de plynômes $P_{A}$. Introduisons  les fonctions symétriques élementaires des racines $x_{i},\:i.e$ les n nombres
$$ \begin{array}{ccc}
    \sigma_{1} & = & x_{1}+x_{2}+\cdots+x_{n} \\
    \sigma_{2} & = & \sum_{i>j}x_{i}x_{j} \\
    \sigma_{3} & = & \sum_{i>j>k}x_{i}x_{j}x_{k} \\
    \vdots & \vdots & \vdots \\
    \sigma_{n}& = & x_{1}x_{2}\cdots x_{n} 
    \end{array}$$
Il est connu que les $\sigma_{i}$ sont liées aux coefficient $a_{i}$ du polynôme $P_{A}$ par la rélation $\sigma_{i}=(-1)^i\frac{a_{i}}{a_{0}}$.
On sait que toutes fonction symétrique de racine peut s'éxprimer comme une fonction des $\sigma_{i}$, donc comme une fonction des coefficient $a_{i}$.
En particulier, considérons pour tout $k \in \mathbb{N}$ la somme de Newton des $x_{i}$:
$$ \begin{array}{ccc}
    S_{1} & = & x_{1}+x_{2}+\cdots+x_{n} \\
    S_{2} & = & x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2} \\
    \vdots & \vdots & \vdots \\
    S_{k} & = & x_{1}^{k}+x_{2}^{k}+\cdots+x_{n}^{k}
    \end{array}$$ 
Les somme $S_{k}$ sont reliée aux coefficient $a_{i}$ par les formule dite de Newton
$$ \begin{array}{ccc}
    a_{1} & = & -a_{0}S_{1} \\
    a_{1}S_{1}+2a_{2} & = & -a_{0}S_{1} \; (a_{1}S_{1}+a_{0}S_{2}=2a_{2}) \\
    a_{1}S_{2}+a_{1}+3a_{3} & = & -a_{0}S_{3} \; (a_{1}S_{2}+a_{2}S_{1}+a_{0}S_{3}=3a_{3}) \\
    \vdots & \vdots & \vdots \\
    a_{1}S_{k-1}+a_{2}S{k-2}+\cdots+ka_{k} & = & -a_{0}S_{k} 
    \end{array}$$
Connaissant les $S_{k}$, il suffit de résoudre un système linéaire triangulaire pour calculer les coefficients $\frac{a_{i}}{a_{0}}$.
or les $S_{k}$ sont facilement accessible des que l'on connait la puissance $A^{k}$ de la matrice A.
en effet $S_{1}=x_{1}+x_{2}+\cdots+x_{n}$ est égale à la trace de A. $S_{k}$ n'est autre que la trace de $A^{k}$ car si  $x_{1},X_{2},\cdots,x_{n}$ sont les valeurs propres d'une matrice  A, $x_{1}^{k},x_{2}^{k},\cdots,x_{n}^{k}$ sont les valeurs propres de la matrice $A^{k}$.
Nou avons donc une méthode qui fournit exactement les coefficient des polynôme caractéristique. Il faut fournir les puissances succéssives de A, calculer $A^{2}$ révient a calculer $n^2$ produit scalaire dans $\mathbb{R}^{n}$, soit éffectuer $n^{3}$ multiplication. Pour former $A_{k}=A.A^{k-1}$,
 en connaissant $A^{k-1}$, il faut également $n^{3}$ multiplication. Le cout total de la méthode est donc de l'ordre $n^{4}$ multiplication.
\end{document}
